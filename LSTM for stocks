import pandas as pd
import os
def read_xls(path):
    data = []
    for file in os.walk(path):
        for each_list in file[2]:
            file_path=file[0]+"/"+each_list
            f = open(file_path,'rb')
            df = pd.read_excel(f)
            df1 = df[['open','high','low','close','vol']]
            df1 = df1[::-1]
            df1.reset_index(drop=True, inplace=True)
            data.append(df1)
            f.close()
    return data
xpath=r"C:\Users\Administrator\Desktop\data"
data = read_xls(xpath)


import numpy as np

data_new = data.copy()
for i in range(len(data)):
    try:
        if len(data_new[i]) < 31:
            del data_new[i]
    except:
        continue

for i in range(len(data)):
    try:
        if len(data_new[i]) < 31:
            del data_new[i]
    except:
        continue

for i in range(len(data_new)):
    if len(data_new[i]) < 31:
        print(i)

print(len(data))
print(len(data_new))
print(len(data_new[0]))
a = np.array(data_new[0])
print(len(a[0]))

raw_data = np.zeros((len(data_new), len(data_new[0]), len(a[0])))
for i in range(len(data_new)):
    raw_data[i] = np.array(data_new[i].values)
print(raw_data.shape)


from sklearn.preprocessing import MinMaxScaler

training_set_size = int(raw_data.shape[0] * 0.7)
test_set_size = raw_data.shape[0] - training_set_size

np.random.shuffle(raw_data)
xy_train = raw_data[:training_set_size]
xy_test = raw_data[training_set_size:]

seq_length = raw_data.shape[1] - 1
data_dim = raw_data.shape[2]
output_dim = 1

xy_train = xy_train.reshape((-1, data_dim))
scaler = MinMaxScaler()
xy_train = scaler.fit_transform(xy_train)
xy_train = xy_train.reshape((-1, seq_length + 1, data_dim))

xy_test = xy_test.reshape((-1, data_dim))
xy_test = scaler.transform(xy_test)
xy_test = xy_test.reshape((-1, seq_length + 1, data_dim))

x_train = np.zeros((training_set_size, seq_length, data_dim))
y_train = np.zeros(training_set_size)
x_test = np.zeros((test_set_size, seq_length, data_dim))
y_test = np.zeros(test_set_size)

for i in range(training_set_size):
    y_train[i] = xy_train[i,-1,3] * 10
x_train = xy_train[:,:-1]

for i in range(test_set_size):
    y_test[i] = xy_test[i,-1,3]  * 10
x_test = xy_test[:,:-1]

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)


from keras.layers import Input, Dense, LSTM, Reshape
from keras.models import Model
from keras import regularizers

# 构建神经网络层 1层Dense层+1层LSTM层+1层Dense层
# 用于1个输入情况
rnn_units = 10
Dense_input = Input(shape=(seq_length, data_dim), name='dense_input')#shape: 形状元组（整型）不包括batch size。表示了预期的输入将是一批（seq_len,6）的向量。
Dense_output_1 = Dense(rnn_units, activation='relu', kernel_regularizer=regularizers.l2(0.01), name='dense1')(Dense_input)#全连接网络

lstm_input = Reshape(target_shape=(seq_length, rnn_units), name='reshape2')(Dense_output_1)
lstm_output = LSTM(rnn_units, activation='tanh', dropout=1.0, name='lstm')(lstm_input)#LSTM网络
#units: Positive integer,dimensionality of the output space.
#dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.

Dense_input_2 = Reshape(target_shape=(rnn_units,), name='reshape3')(lstm_output)
Dense_output_2 = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01), name='dense2')(Dense_input_2)#全连接网络
Dense_output_3 = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.01), name='dense3')(Dense_output_2)#全连接网络
predictions = Dense(output_dim, activation=None, kernel_regularizer=regularizers.l2(0.01), name='dense4')(Dense_output_3)#全连接网络

model = Model(inputs=Dense_input, outputs=predictions)
#This model will include all layers required in the computation of output given input.
model.compile(optimizer='adam', loss='mse', metrics=['mae'])
#Configures the model for training.
#optimizer: String (name of optimizer) or optimizer instance. See optimizers.
#loss: String (name of objective function) or objective function.The loss value will be minimized by the model.
#metrics: List of metrics to be evaluated by the model during training and testing. Typically you will use  metrics=['accuracy'].
history = model.fit(x_train, y_train, batch_size=256, epochs=200, verbose=2, validation_split=0.1)
#Trains the model for a given number of epochs (iterations on a dataset).
#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.


import matplotlib.pyplot as plt
# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()


trainPredict2 = model.predict(x_train)
trainPredict2_2 = trainPredict2 / 10 * scaler.data_range_[3] + scaler.data_min_[3]
trainY2 = y_train / 10 * scaler.data_range_[3] + scaler.data_min_[3]
plt.figure(figsize=(8,8))
plt.xlim((0,10))
plt.ylim((0,10))
plt.scatter(y_train, trainPredict2)
plt.ylabel('prediction')
plt.xlabel('label')


count = 0
for i in range(len(trainY2)):
    if (trainPredict2_2[i] - trainY2[i]) / trainY2[i] * 100 <= 5:
        count += 1
count = count / len(trainY2) * 100
print(count)


testPredict2 = model.predict(x_test)
testPredict2_2 = testPredict2 / 10 * scaler.data_range_[3] + scaler.data_min_[3]
testY2 = y_test / 10 * scaler.data_range_[3] + scaler.data_min_[3]
plt.figure(figsize=(8,8))
plt.xlim((0,10))
plt.ylim((0,10))
plt.scatter(y_test, testPredict2)
plt.ylabel('prediction')
plt.xlabel('label')


count = 0
for i in range(len(testY2)):
    if (testPredict2_2[i] - testY2[i]) / testY2[i] * 100 <= 5:
        count += 1
count = count / len(testY2) * 100
print(count)
